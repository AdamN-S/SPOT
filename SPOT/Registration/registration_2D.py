# -*- coding: utf-8 -*-
"""
Created on Tue Sep  3 01:16:11 2019

@author: felix
"""

def translation_register_correlation(vid1, 
                                     vid2map, 
                                     sub_pix_res=1, 
                                     impute_pixels=True, 
                                     use_registered=True):
    r""" Frame-by-frame translation registration using phase cross-correlation 
    
    Parameters
    ----------
    vid1 : (n_frames, n_rows, n_cols) video
        the input uint8 video to compute the registration transforms with. Typically this is some transformed image which may be easier to register than the original raw intensities such as the gradient image. 
    vid2map : (n_frames, n_rows, n_cols) videos
        the input uint8 video that is desired to apply the learnt registration transforms to 
    sub_pix_res : int
        Upsampling factor. Images will be registered to within 1 / upsample_factor of a pixel.
    impute_pixels : bool
        When images are shifted and warped by the registration transform, missing pixels are given the value 0. When impute_pixels=True, instead of 0 these pixels are given the mean intensity of the warped frame instead. This helps to stabilise the registration when the displacement is very large. 
    use_registered : bool
        if True, the next displacement is found from registering the non-registered next frame to the registered previous frame. if False, the displacements are found pairwise between successive frames, then to register say frame 10, the composite displacement, the cumulative sum of all displacements from frame 1 to 10 are found and then applied. 
    
    Returns
    -------
    registered_vid : (n_frames, n_rows, n_cols) videos
        the translation registered input uint8 vid2map video
    disps : (n_frames-1, 2) array
        the (x,y) translation displacements generated by translation_register_correlation function above. 

    """
    try:
        from skimage.feature import register_translation
    except:
        from skimage.registration import phase_cross_correlation as register_translation
    import numpy as np 
    import cv2
    from tqdm import tqdm 
    
    n_frames = len(vid1)
    registered_vid = [vid2map[0][None,:]]
    registered_vid_ref = [vid1[0]]
    disps = []
    
    flag = 1

    for i in tqdm(np.arange(1, n_frames)):
        
        if use_registered:
            frame1 = registered_vid_ref[-1]
        else:
            frame1 = vid1[i-1] 
#            frame1 = vid1[0] 

        # a problem with frame1 is drift caused by too many blank pixels producing an artificial 'edge'
        if impute_pixels:
            frame1[frame1==0] = np.nanmean(frame1[frame1>0]) # cast to uint8 if required.
            frame1 = np.uint8(frame1)

        frame2 = np.uint8(vid1[i])
        frame2map = np.uint8(vid2map[i])
        
        # subpixel translation precision
#        shift, error, diffphase = register_translation(sobel(frame1), sobel(frame2))
        shift, error, diffphase = register_translation(frame1, frame2)
        
        shift = -shift[::-1] # to put in (x,y convention of opencv)

        disps.append(shift)
        
        if use_registered:
            correction_shift = shift.copy()
        else:
            correction_shift = np.sum(np.vstack(disps), axis=0)

        height, width = frame1.shape[:2]
        R2 = np.dstack(np.meshgrid(np.arange(width), np.arange(height)))
        
        # remapping and interpolation 
        pixel_map = R2 + correction_shift[None,None,:]
        #print(pixel_map.shape)
        pixel_map = np.array(pixel_map, dtype=np.float32)
        
        #new_ref2 = cv2.remap(np.uint8(frame2), pixel_map[:,:,0], pixel_map[:,:,1], interpolation=cv2.INTER_LINEAR)
        new_ref2 = cv2.remap(np.float32(frame2), pixel_map[:,:,0], pixel_map[:,:,1], interpolation=cv2.INTER_LINEAR)
        new_frame2 = cv2.remap(frame2map, pixel_map[:,:,0], pixel_map[:,:,1], interpolation=cv2.INTER_LINEAR)

        registered_vid_ref.append(new_ref2)
        registered_vid.append(new_frame2[None,:])
        
    registered_vid = np.concatenate(registered_vid, axis=0)
    disps = np.vstack(disps)
    
    return registered_vid, disps # return the disps.
    

def apply_translation_register_correlation(vid2map, 
                                           disps, 
                                           use_registered=True):
    r""" Apply the learnt translation registration parameters from one video to another video e.g. a second video channel 
    
    Parameters
    ----------
    vid2map : (n_frames, n_rows, n_cols) videos
        the input uint8 video that is desired to apply the learnt registration transforms to 
    disps : (n_frames-1, 2) array
        the (x,y) translation displacements generated by translation_register_correlation function above. 
    use_registered : bool
        if True, the next displacement is found from registering the non-registered next frame to the registered previous frame. if False, the displacements are found pairwise between successive frames, then to register say frame 10, the composite displacement, the cumulative sum of all displacements from frame 1 to 10 are found and then applied. 
    
    Returns
    -------
    registered_vid : (n_frames, n_rows, n_cols) videos
        the translation registered input uint8 vid2map video

    """
    try:
        from skimage.feature import register_translation
    except:
        from skimage.registration import phase_cross_correlation as register_translation
    import numpy as np 
    import cv2
    from tqdm import tqdm 
    
    n_frames = len(vid2map)
    registered_vid = [vid2map[0][None,:]]
    
    for i in tqdm(np.arange(1, n_frames)):
        
        frame2map = vid2map[i].copy()
        
        if use_registered:
            correction_shift = disps[i-1].copy()
        else:
            correction_shift = np.sum(np.vstack(disps[:i]), axis=0)

        height, width = frame2map.shape[:2]
        R2 = np.dstack(np.meshgrid(np.arange(width), np.arange(height)))
        
        # remapping and interpolation 
        pixel_map = R2 + correction_shift[None,None,:]
        #print(pixel_map.shape)
        pixel_map = np.array(pixel_map, dtype=np.float32)
        
        new_frame2 = cv2.remap(frame2map, pixel_map[:,:,0], pixel_map[:,:,1], interpolation=cv2.INTER_LINEAR)
        
        registered_vid.append(new_frame2[None,:])
        
    registered_vid = np.concatenate(registered_vid, axis=0)
    
    return registered_vid


def translation_register_blurry_phase_contrast_videos(vid, 
                                                      shape=(512,512), 
                                                      sub_pix_res=1, 
                                                      impute_pixels=True, 
                                                      use_registered=True, 
                                                      use_dog=True, 
                                                      dog_sigma=15, 
                                                      detect_blurred_frames = False, 
                                                      blur_factor=1., 
                                                      apply_crop_mask=True,
                                                      return_crop=False):
    r""" Main function for registering brightfield and phase contrast microscopy videos. Optionally pre-runs a blur frame detection and throws out blurry frames prior to frame-to-frame translation registration correction.

    Parameters
    ----------
    vid : (n_frames, n_rows, n_cols) array
        input grayscale phase contrast or brightfield microscopy video to register
    shape : None or (n_rows, n_cols) tuple
        specifies the target shape to resize the video. Resizing is recommended for speeding up and also the pretrained CNN detection and segmentation models were both trained with 512x512 image sizes. 
    sub_pix_res : int 
        Upsampling factor. Images will be registered to within 1 / upsample_factor of a pixel. Used by the translation registration algorithm
    impute_pixels : bool
        When images are shifted and warped by the registration transform, missing pixels are given the value 0. When impute_pixels=True, instead of 0 these pixels are given the mean intensity of the warped frame instead. This helps to stabilise the registration when the displacement is very large. 
    use_registered : bool
        if True, the next displacement is found from registering the non-registered next frame to the registered previous frame. if False, the displacements are found pairwise between successive frames, then to register say frame 10, the composite displacement, the cumulative sum of all displacements from frame 1 to 10 are found and then applied. 
    use_dog : bool
        if True, uses the difference of Gaussian image, computed with second sigma given by dog_sigma variable for getting the registration transforms. This is recommended as it is generally more robust for weak contrast images.
    dog_sigma : float
        if use_dog=True, this is the second sigma. The dog image or difference of Gaussian image is computed as img - ndimage.gaussian_filter(img, sigma=dog_sigma)
    blur_factor : float
        the blur frame detection is based on mean+blur_factor*std thresholding on the absolute magnitude of the frame to frame sobel image squared. The higher the blur_factor the higher the blur has to be before a frame is dropped.
    apply_crop_mask : bool
        if True, the video is cropped so as to ensure no pixels in the final cropped registered video contains an intensity of 0 which may have been introduced due to applying the registration translation 
    
    Returns
    -------
    stacked_video_translation : (n_frames_new, n_rows_new, n_cols_new) array
        output translation corrected grayscale, potentially resized and cropped phase contrast/brightfield microscopy video with blurred frames dropped
    blurred_frames : list
        list of all frames that were detected to be blurred. Will be empty if blur detection is not enabled or no blurred frames were detected at the specified cutoff value
    
    """
    import skimage.transform as sktform 
    import skimage.filters as skfilters 
    import scipy.ndimage as ndimage 
    import numpy as np 

    stacked_video_resize = vid.copy()

    if shape is not None:
        stacked_video_resize = np.array([np.uint8(sktform.resize(vv, shape, preserve_range=True)) for vv in vid])


    # =============================================================================
    #       use the sobel signature to detect frames that dramatically drop and are therefore blurred which can mess up the registration. 
    # =============================================================================

    if detect_blurred_frames:  
        # global detection and removal of blurry frames. 
        edges = np.hstack([np.abs(skfilters.sobel(vv)**2).mean() for vv in stacked_video_resize])
        change_edges = np.abs(np.diff(edges))
        
        thresh = np.mean(change_edges) + blur_factor*np.std(change_edges)

        blurred_frames = np.arange(len(change_edges))[change_edges>=thresh]+1
    else:
        blurred_frames = [] # all empty

    # drop blurry frames
    stacked_video_resize = np.array([stacked_video_resize[jj] for jj in np.arange(len(stacked_video_resize)) if jj not in blurred_frames])
    
    if use_dog: 
        # 1. try dog. -> this already makes it better. 
        stacked_video_resize_dog = np.array([stacked_video_resize[jj]*1. - ndimage.gaussian_filter(stacked_video_resize[jj], sigma=dog_sigma)*1. for jj in np.arange(len(stacked_video_resize))])
        stacked_video_resize_dog = np.abs(stacked_video_resize_dog)
        stacked_video_resize_dog = (stacked_video_resize_dog-stacked_video_resize_dog.min()) / (stacked_video_resize_dog.max() - stacked_video_resize_dog.min())
        stacked_video_resize_dog = np.uint8(255*stacked_video_resize_dog)
    else:
        stacked_video_resize_dog = stacked_video_resize.copy()
    
    # =============================================================================
    #       Registration 
    # =============================================================================
    
    stacked_video_translation, disps = translation_register_correlation(stacked_video_resize_dog,  # this is the video we use to register. 
                                                                        stacked_video_resize, 
                                                                        sub_pix_res=sub_pix_res,
                                                                        impute_pixels=impute_pixels,
                                                                        use_registered=use_registered)
    if apply_crop_mask:
        crop_mask = np.min(stacked_video_translation, axis=0)
            
        YY, XX = np.indices(crop_mask.shape)
        min_X = np.min(XX[crop_mask> 0 ])
        max_X = np.max(XX[crop_mask> 0])
        min_Y = np.min(YY[crop_mask> 0 ])
        max_Y = np.max(YY[crop_mask> 0])
        
        stacked_video_translation = stacked_video_translation[:,min_Y:max_Y, min_X:max_X].copy()
        
        crop_bbox = np.hstack([min_X,min_Y,max_X, max_Y])
        
        if return_crop:
            return stacked_video_translation, blurred_frames, disps, crop_bbox
        else:
            return stacked_video_translation, blurred_frames, disps
    else:
        return stacked_video_translation, blurred_frames, disps
   
